{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7JOZu8Vk9PJ",
        "outputId": "eae5d56b-97c6-4dbe-8e86-f8842a8c1fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BOpBlThiaY2"
      },
      "outputs": [],
      "source": [
        "path=\"/content/drive/MyDrive/Project/ImagePro\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "DeD-ZXC1jSx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files=os.listdir(path)"
      ],
      "metadata": {
        "id": "ErHIKWVkjpta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.sort()\n",
        "print(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_qwjtLfjtgT",
        "outputId": "bbcec7f3-938f-47e1-de37-16f904a4f27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_array=[]\n",
        "label_array=[]"
      ],
      "metadata": {
        "id": "V9x4DrJQlDdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loop thru each file in files\n",
        "for i in tqdm(range(len(files))):\n",
        "    #list of image in each folder\n",
        "    sub_file=os.listdir(path+\"/\"+files[i])\n",
        "\n",
        "    #loop thru each sub folder\n",
        "    for j in range(len(sub_file)):\n",
        "        file_path=path+\"/\"+files[i]+\"/\"+sub_file[j]\n",
        "        image=cv2.imread(file_path)\n",
        "        image=cv2.resize(image,(96,96))\n",
        "        image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "        image_array.append(image)\n",
        "        label_array.append(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUg2UIsmlE8A",
        "outputId": "8424feff-0fd3-4d2c-8179-0f133e26b3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [08:26<00:00, 19.48s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_array=np.array(image_array)\n",
        "label_array=np.array(label_array,dtype=\"float\")"
      ],
      "metadata": {
        "id": "E75fQXpolI9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(image_array,label_array,test_size=0.15)\n",
        "#xtrain will have 85% images and xtest will have 15% images\n"
      ],
      "metadata": {
        "id": "P0z1269slLEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del image_array, label_array"
      ],
      "metadata": {
        "id": "qyFmBPQHlYO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6O9H_7YlavY",
        "outputId": "971e356c-f8bc-41eb-ae89-c9b3978e2b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers,callbacks,utils,applications,optimizers\n",
        "from keras.models import Sequential,Model,load_model"
      ],
      "metadata": {
        "id": "kvtmcWURlLcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "#add pretrained model to sequential model. adding EfficientNetB0-TRANSFER LEARNING used\n",
        "pretrained_model=tf.keras.applications.EfficientNetB0(input_shape=(96,96,3),include_top=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFylwhSqlL69",
        "outputId": "fbbf7329-842e-4202-d0d9-053ed844e357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(pretrained_model)"
      ],
      "metadata": {
        "id": "WuwYt4hGlMOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add pooling to model\n",
        "model.add(layers.GlobalAveragePooling2D())"
      ],
      "metadata": {
        "id": "6bnqPgB3lMgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add dropout to model\n",
        "#we add dropout to increase accuracy by reducing overfitting\n",
        "model.add(layers.Dropout(0.3))"
      ],
      "metadata": {
        "id": "YPCHnISAlMyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add dense layer as output\n",
        "model.add(layers.Dense(1))"
      ],
      "metadata": {
        "id": "mxIuH511lNCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None,96,96,3))"
      ],
      "metadata": {
        "id": "O6LuLKrylNbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIafDcT0lNtB",
        "outputId": "9cab7ed8-ea91-4050-d7c1-0699f9ccad9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb0 (Functional  (None, 3, 3, 1280)        4049571   \n",
            " )                                                               \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 1280)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 1281      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4050852 (15.45 MB)\n",
            "Trainable params: 4008829 (15.29 MB)\n",
            "Non-trainable params: 42023 (164.16 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile model\n",
        "model.compile(optimizer=\"adam\",loss=\"mae\",metrics=[\"mae\"])"
      ],
      "metadata": {
        "id": "V0fp8wiLlxuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create checkpoint to save best accuracy model\n",
        "ckp_path=\"trained_model/model\"\n",
        "model_checkpoint=tf.keras.callbacks.ModelCheckpoint(\n",
        "filepath=ckp_path,\n",
        "monitor=\"val_mae\",\n",
        "mode=\"auto\",\n",
        "save_best_only=True,\n",
        "save_weights_only=True)"
      ],
      "metadata": {
        "id": "-gbPqmVMlyNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create learning rate reducer to reduce lr when accuracy does not improve\n",
        "reduce_lr=tf.keras.callbacks.ReduceLROnPlateau(\n",
        "factor=0.9, monitor=\"val_mae\", mode=\"auto\",cooldown=0,patience=5,verbose=1,min_lr=1e-6)"
      ],
      "metadata": {
        "id": "sYIUFs_AlysQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start training the model\n",
        "Epochs=100\n",
        "Batch_Size=32"
      ],
      "metadata": {
        "id": "PGUZndkAly9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train,\n",
        "                  Y_train,\n",
        "                  validation_data=(X_test,Y_test),\n",
        "                  batch_size=Batch_Size,\n",
        "                  epochs=Epochs,\n",
        "                  callbacks=[model_checkpoint,reduce_lr]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk74eljllzU9",
        "outputId": "7e8007a1-c0a9-4026-eff1-ebe4468378d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "316/316 [==============================] - 68s 81ms/step - loss: 3.0734 - mae: 3.0734 - val_loss: 2.2279 - val_mae: 2.2279 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "316/316 [==============================] - 22s 68ms/step - loss: 1.2692 - mae: 1.2692 - val_loss: 0.8391 - val_mae: 0.8391 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.8956 - mae: 0.8956 - val_loss: 1.0708 - val_mae: 1.0708 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "316/316 [==============================] - 22s 68ms/step - loss: 0.7369 - mae: 0.7369 - val_loss: 0.4661 - val_mae: 0.4661 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.6536 - mae: 0.6536 - val_loss: 0.5882 - val_mae: 0.5882 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.5898 - mae: 0.5898 - val_loss: 0.8362 - val_mae: 0.8362 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.5428 - mae: 0.5428 - val_loss: 0.6203 - val_mae: 0.6203 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.4983 - mae: 0.4983 - val_loss: 0.6420 - val_mae: 0.6420 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.4952 - mae: 0.4952 - val_loss: 0.4492 - val_mae: 0.4492 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.5656 - mae: 0.5656 - val_loss: 0.5075 - val_mae: 0.5075 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.5924 - mae: 0.5924 - val_loss: 0.7369 - val_mae: 0.7369 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "316/316 [==============================] - 22s 70ms/step - loss: 0.4920 - mae: 0.4920 - val_loss: 0.3267 - val_mae: 0.3267 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.4160 - mae: 0.4160 - val_loss: 0.3276 - val_mae: 0.3276 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.4030 - mae: 0.4030 - val_loss: 0.4444 - val_mae: 0.4444 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.4002 - mae: 0.4002 - val_loss: 0.3558 - val_mae: 0.3558 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "316/316 [==============================] - 20s 64ms/step - loss: 0.3771 - mae: 0.3771 - val_loss: 0.4626 - val_mae: 0.4626 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "316/316 [==============================] - ETA: 0s - loss: 0.4442 - mae: 0.4442\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.4442 - mae: 0.4442 - val_loss: 0.5190 - val_mae: 0.5190 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.3743 - mae: 0.3743 - val_loss: 0.4220 - val_mae: 0.4220 - lr: 9.0000e-04\n",
            "Epoch 19/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.4215 - mae: 0.4215 - val_loss: 0.3709 - val_mae: 0.3709 - lr: 9.0000e-04\n",
            "Epoch 20/100\n",
            "316/316 [==============================] - 22s 70ms/step - loss: 0.4013 - mae: 0.4013 - val_loss: 0.2374 - val_mae: 0.2374 - lr: 9.0000e-04\n",
            "Epoch 21/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.3435 - mae: 0.3435 - val_loss: 0.3018 - val_mae: 0.3018 - lr: 9.0000e-04\n",
            "Epoch 22/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.3587 - mae: 0.3587 - val_loss: 0.2936 - val_mae: 0.2936 - lr: 9.0000e-04\n",
            "Epoch 23/100\n",
            "316/316 [==============================] - 21s 68ms/step - loss: 0.4225 - mae: 0.4225 - val_loss: 0.5879 - val_mae: 0.5879 - lr: 9.0000e-04\n",
            "Epoch 24/100\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.4737 - mae: 0.4737 - val_loss: 0.3641 - val_mae: 0.3641 - lr: 9.0000e-04\n",
            "Epoch 25/100\n",
            "315/316 [============================>.] - ETA: 0s - loss: 0.4177 - mae: 0.4177\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.4183 - mae: 0.4183 - val_loss: 0.2658 - val_mae: 0.2658 - lr: 9.0000e-04\n",
            "Epoch 26/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.4193 - mae: 0.4193 - val_loss: 0.3017 - val_mae: 0.3017 - lr: 8.1000e-04\n",
            "Epoch 27/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.3334 - mae: 0.3334 - val_loss: 0.3100 - val_mae: 0.3100 - lr: 8.1000e-04\n",
            "Epoch 28/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.3175 - mae: 0.3175 - val_loss: 0.2113 - val_mae: 0.2113 - lr: 8.1000e-04\n",
            "Epoch 29/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.3114 - mae: 0.3114 - val_loss: 0.1806 - val_mae: 0.1806 - lr: 8.1000e-04\n",
            "Epoch 30/100\n",
            "316/316 [==============================] - 20s 64ms/step - loss: 0.3035 - mae: 0.3035 - val_loss: 0.3625 - val_mae: 0.3625 - lr: 8.1000e-04\n",
            "Epoch 31/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.2982 - mae: 0.2982 - val_loss: 0.2854 - val_mae: 0.2854 - lr: 8.1000e-04\n",
            "Epoch 32/100\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.2962 - mae: 0.2962 - val_loss: 0.3091 - val_mae: 0.3091 - lr: 8.1000e-04\n",
            "Epoch 33/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2846 - mae: 0.2846 - val_loss: 0.2013 - val_mae: 0.2013 - lr: 8.1000e-04\n",
            "Epoch 34/100\n",
            "316/316 [==============================] - ETA: 0s - loss: 0.2847 - mae: 0.2847\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
            "316/316 [==============================] - 21s 68ms/step - loss: 0.2847 - mae: 0.2847 - val_loss: 0.3157 - val_mae: 0.3157 - lr: 8.1000e-04\n",
            "Epoch 35/100\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.3739 - mae: 0.3739 - val_loss: 0.9151 - val_mae: 0.9151 - lr: 7.2900e-04\n",
            "Epoch 36/100\n",
            "316/316 [==============================] - 21s 68ms/step - loss: 0.3370 - mae: 0.3370 - val_loss: 0.4548 - val_mae: 0.4548 - lr: 7.2900e-04\n",
            "Epoch 37/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.2966 - mae: 0.2966 - val_loss: 0.2644 - val_mae: 0.2644 - lr: 7.2900e-04\n",
            "Epoch 38/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.2802 - mae: 0.2802 - val_loss: 0.2305 - val_mae: 0.2305 - lr: 7.2900e-04\n",
            "Epoch 39/100\n",
            "316/316 [==============================] - ETA: 0s - loss: 0.2961 - mae: 0.2961\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.2961 - mae: 0.2961 - val_loss: 0.2506 - val_mae: 0.2506 - lr: 7.2900e-04\n",
            "Epoch 40/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.3012 - mae: 0.3012 - val_loss: 0.3816 - val_mae: 0.3816 - lr: 6.5610e-04\n",
            "Epoch 41/100\n",
            "316/316 [==============================] - 24s 75ms/step - loss: 0.2729 - mae: 0.2729 - val_loss: 0.3625 - val_mae: 0.3625 - lr: 6.5610e-04\n",
            "Epoch 42/100\n",
            "316/316 [==============================] - 27s 86ms/step - loss: 0.2793 - mae: 0.2793 - val_loss: 0.2378 - val_mae: 0.2378 - lr: 6.5610e-04\n",
            "Epoch 43/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2777 - mae: 0.2777 - val_loss: 0.2046 - val_mae: 0.2046 - lr: 6.5610e-04\n",
            "Epoch 44/100\n",
            "316/316 [==============================] - 23s 74ms/step - loss: 0.2701 - mae: 0.2701 - val_loss: 0.1465 - val_mae: 0.1465 - lr: 6.5610e-04\n",
            "Epoch 45/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.2657 - mae: 0.2657 - val_loss: 0.1969 - val_mae: 0.1969 - lr: 6.5610e-04\n",
            "Epoch 46/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2563 - mae: 0.2563 - val_loss: 0.1877 - val_mae: 0.1877 - lr: 6.5610e-04\n",
            "Epoch 47/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2457 - mae: 0.2457 - val_loss: 0.1782 - val_mae: 0.1782 - lr: 6.5610e-04\n",
            "Epoch 48/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2444 - mae: 0.2444 - val_loss: 0.2019 - val_mae: 0.2019 - lr: 6.5610e-04\n",
            "Epoch 49/100\n",
            "316/316 [==============================] - ETA: 0s - loss: 0.2500 - mae: 0.2500\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2500 - mae: 0.2500 - val_loss: 0.1849 - val_mae: 0.1849 - lr: 6.5610e-04\n",
            "Epoch 50/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2630 - mae: 0.2630 - val_loss: 0.2121 - val_mae: 0.2121 - lr: 5.9049e-04\n",
            "Epoch 51/100\n",
            "316/316 [==============================] - 20s 64ms/step - loss: 0.2567 - mae: 0.2567 - val_loss: 0.1729 - val_mae: 0.1729 - lr: 5.9049e-04\n",
            "Epoch 52/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2600 - mae: 0.2600 - val_loss: 0.4994 - val_mae: 0.4994 - lr: 5.9049e-04\n",
            "Epoch 53/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.3078 - mae: 0.3078 - val_loss: 0.3625 - val_mae: 0.3625 - lr: 5.9049e-04\n",
            "Epoch 54/100\n",
            "315/316 [============================>.] - ETA: 0s - loss: 0.2717 - mae: 0.2717\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.2716 - mae: 0.2716 - val_loss: 0.1947 - val_mae: 0.1947 - lr: 5.9049e-04\n",
            "Epoch 55/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2683 - mae: 0.2683 - val_loss: 0.1985 - val_mae: 0.1985 - lr: 5.3144e-04\n",
            "Epoch 56/100\n",
            "316/316 [==============================] - 20s 63ms/step - loss: 0.2525 - mae: 0.2525 - val_loss: 0.2300 - val_mae: 0.2300 - lr: 5.3144e-04\n",
            "Epoch 57/100\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.2397 - mae: 0.2397 - val_loss: 0.2707 - val_mae: 0.2707 - lr: 5.3144e-04\n",
            "Epoch 58/100\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.2624 - mae: 0.2624 - val_loss: 0.2445 - val_mae: 0.2445 - lr: 5.3144e-04\n",
            "Epoch 59/100\n",
            "315/316 [============================>.] - ETA: 0s - loss: 0.2438 - mae: 0.2438\n",
            "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.2438 - mae: 0.2438 - val_loss: 0.3297 - val_mae: 0.3297 - lr: 5.3144e-04\n",
            "Epoch 60/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2286 - mae: 0.2286 - val_loss: 0.1871 - val_mae: 0.1871 - lr: 4.7830e-04\n",
            "Epoch 61/100\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.2300 - mae: 0.2300 - val_loss: 0.2933 - val_mae: 0.2933 - lr: 4.7830e-04\n",
            "Epoch 62/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2294 - mae: 0.2294 - val_loss: 0.2322 - val_mae: 0.2322 - lr: 4.7830e-04\n",
            "Epoch 63/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.2305 - mae: 0.2305 - val_loss: 0.1671 - val_mae: 0.1671 - lr: 4.7830e-04\n",
            "Epoch 64/100\n",
            "316/316 [==============================] - ETA: 0s - loss: 0.2238 - mae: 0.2238\n",
            "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
            "316/316 [==============================] - 20s 64ms/step - loss: 0.2238 - mae: 0.2238 - val_loss: 0.2293 - val_mae: 0.2293 - lr: 4.7830e-04\n",
            "Epoch 65/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.2294 - mae: 0.2294 - val_loss: 0.1387 - val_mae: 0.1387 - lr: 4.3047e-04\n",
            "Epoch 66/100\n",
            "316/316 [==============================] - 20s 65ms/step - loss: 0.2217 - mae: 0.2217 - val_loss: 0.1954 - val_mae: 0.1954 - lr: 4.3047e-04\n",
            "Epoch 67/100\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.2218 - mae: 0.2218 - val_loss: 0.1881 - val_mae: 0.1881 - lr: 4.3047e-04\n",
            "Epoch 68/100\n",
            "316/316 [==============================] - 20s 64ms/step - loss: 0.2180 - mae: 0.2180 - val_loss: 0.2031 - val_mae: 0.2031 - lr: 4.3047e-04\n",
            "Epoch 69/100\n",
            "316/316 [==============================] - 20s 64ms/step - loss: 0.2182 - mae: 0.2182 - val_loss: 0.1535 - val_mae: 0.1535 - lr: 4.3047e-04\n",
            "Epoch 70/100\n",
            "315/316 [============================>.] - ETA: 0s - loss: 0.2210 - mae: 0.2210\n",
            "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.2209 - mae: 0.2209 - val_loss: 0.2100 - val_mae: 0.2100 - lr: 4.3047e-04\n",
            "Epoch 71/100\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.2205 - mae: 0.2205 - val_loss: 0.1717 - val_mae: 0.1717 - lr: 3.8742e-04\n",
            "Epoch 72/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.2203 - mae: 0.2203 - val_loss: 0.1409 - val_mae: 0.1409 - lr: 3.8742e-04\n",
            "Epoch 73/100\n",
            "316/316 [==============================] - 22s 68ms/step - loss: 0.2176 - mae: 0.2176 - val_loss: 0.1125 - val_mae: 0.1125 - lr: 3.8742e-04\n",
            "Epoch 74/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2158 - mae: 0.2158 - val_loss: 0.1064 - val_mae: 0.1064 - lr: 3.8742e-04\n",
            "Epoch 75/100\n",
            "316/316 [==============================] - 22s 68ms/step - loss: 0.2192 - mae: 0.2192 - val_loss: 0.2003 - val_mae: 0.2003 - lr: 3.8742e-04\n",
            "Epoch 76/100\n",
            "316/316 [==============================] - 21s 68ms/step - loss: 0.2337 - mae: 0.2337 - val_loss: 0.1621 - val_mae: 0.1621 - lr: 3.8742e-04\n",
            "Epoch 77/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.2209 - mae: 0.2209 - val_loss: 0.2483 - val_mae: 0.2483 - lr: 3.8742e-04\n",
            "Epoch 78/100\n",
            "316/316 [==============================] - 22s 68ms/step - loss: 0.2169 - mae: 0.2169 - val_loss: 0.1667 - val_mae: 0.1667 - lr: 3.8742e-04\n",
            "Epoch 79/100\n",
            "316/316 [==============================] - ETA: 0s - loss: 0.2209 - mae: 0.2209\n",
            "Epoch 79: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2209 - mae: 0.2209 - val_loss: 0.1438 - val_mae: 0.1438 - lr: 3.8742e-04\n",
            "Epoch 80/100\n",
            "316/316 [==============================] - 22s 68ms/step - loss: 0.2116 - mae: 0.2116 - val_loss: 0.1620 - val_mae: 0.1620 - lr: 3.4868e-04\n",
            "Epoch 81/100\n",
            "316/316 [==============================] - 21s 68ms/step - loss: 0.2119 - mae: 0.2119 - val_loss: 0.1250 - val_mae: 0.1250 - lr: 3.4868e-04\n",
            "Epoch 82/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.2173 - mae: 0.2173 - val_loss: 0.1584 - val_mae: 0.1584 - lr: 3.4868e-04\n",
            "Epoch 83/100\n",
            "316/316 [==============================] - 21s 68ms/step - loss: 0.2140 - mae: 0.2140 - val_loss: 0.2254 - val_mae: 0.2254 - lr: 3.4868e-04\n",
            "Epoch 84/100\n",
            "316/316 [==============================] - ETA: 0s - loss: 0.2124 - mae: 0.2124\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 0.00031381062290165574.\n",
            "316/316 [==============================] - 21s 65ms/step - loss: 0.2124 - mae: 0.2124 - val_loss: 0.1384 - val_mae: 0.1384 - lr: 3.4868e-04\n",
            "Epoch 85/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.2102 - mae: 0.2102 - val_loss: 0.1127 - val_mae: 0.1127 - lr: 3.1381e-04\n",
            "Epoch 86/100\n",
            "316/316 [==============================] - 21s 68ms/step - loss: 0.2086 - mae: 0.2086 - val_loss: 0.1614 - val_mae: 0.1614 - lr: 3.1381e-04\n",
            "Epoch 87/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.2066 - mae: 0.2066 - val_loss: 0.1274 - val_mae: 0.1274 - lr: 3.1381e-04\n",
            "Epoch 88/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.2034 - mae: 0.2034 - val_loss: 0.1546 - val_mae: 0.1546 - lr: 3.1381e-04\n",
            "Epoch 89/100\n",
            "316/316 [==============================] - ETA: 0s - loss: 0.2099 - mae: 0.2099\n",
            "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.0002824295632308349.\n",
            "316/316 [==============================] - 22s 70ms/step - loss: 0.2099 - mae: 0.2099 - val_loss: 0.1494 - val_mae: 0.1494 - lr: 3.1381e-04\n",
            "Epoch 90/100\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2013 - mae: 0.2013 - val_loss: 0.2034 - val_mae: 0.2034 - lr: 2.8243e-04\n",
            "Epoch 91/100\n",
            "316/316 [==============================] - 21s 68ms/step - loss: 0.2088 - mae: 0.2088 - val_loss: 0.2354 - val_mae: 0.2354 - lr: 2.8243e-04\n",
            "Epoch 92/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.2086 - mae: 0.2086 - val_loss: 0.1649 - val_mae: 0.1649 - lr: 2.8243e-04\n",
            "Epoch 93/100\n",
            "316/316 [==============================] - 21s 68ms/step - loss: 0.2092 - mae: 0.2092 - val_loss: 0.2010 - val_mae: 0.2010 - lr: 2.8243e-04\n",
            "Epoch 94/100\n",
            "316/316 [==============================] - ETA: 0s - loss: 0.2030 - mae: 0.2030\n",
            "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.00025418660952709616.\n",
            "316/316 [==============================] - 22s 70ms/step - loss: 0.2030 - mae: 0.2030 - val_loss: 0.1687 - val_mae: 0.1687 - lr: 2.8243e-04\n",
            "Epoch 95/100\n",
            "316/316 [==============================] - 22s 71ms/step - loss: 0.2009 - mae: 0.2009 - val_loss: 0.1480 - val_mae: 0.1480 - lr: 2.5419e-04\n",
            "Epoch 96/100\n",
            "316/316 [==============================] - 21s 66ms/step - loss: 0.2006 - mae: 0.2006 - val_loss: 0.1310 - val_mae: 0.1310 - lr: 2.5419e-04\n",
            "Epoch 97/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.1999 - mae: 0.1999 - val_loss: 0.1932 - val_mae: 0.1932 - lr: 2.5419e-04\n",
            "Epoch 98/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.2020 - mae: 0.2020 - val_loss: 0.1684 - val_mae: 0.1684 - lr: 2.5419e-04\n",
            "Epoch 99/100\n",
            "316/316 [==============================] - ETA: 0s - loss: 0.2004 - mae: 0.2004\n",
            "Epoch 99: ReduceLROnPlateau reducing learning rate to 0.00022876793809700757.\n",
            "316/316 [==============================] - 21s 67ms/step - loss: 0.2004 - mae: 0.2004 - val_loss: 0.2071 - val_mae: 0.2071 - lr: 2.5419e-04\n",
            "Epoch 100/100\n",
            "316/316 [==============================] - 22s 69ms/step - loss: 0.1993 - mae: 0.1993 - val_loss: 0.1122 - val_mae: 0.1122 - lr: 2.2877e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#after training load best model\n",
        "model.load_weights(ckp_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DivuD9uJl8ti",
        "outputId": "e7c38bbb-e7e6-4516-a791-d20880891f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7a1c722ff820>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert model to tensorflow lite model\n",
        "converter=tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model=converter.convert()"
      ],
      "metadata": {
        "id": "sWN4NlvLl9sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "with open(\"model.tflite\",\"wb\") as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "dwFOIXWOl9_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to see prediction result on test dataset\n",
        "prediction_val=model.predict(X_test,batch_size=32)\n",
        "#print 1st 10 values\n",
        "print(prediction_val[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKAknpxwl-hP",
        "outputId": "9060930b-d651-45d8-b2eb-c8ee0916c4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 3s 15ms/step\n",
            "[[19.12621  ]\n",
            " [ 9.013281 ]\n",
            " [21.109003 ]\n",
            " [10.045968 ]\n",
            " [23.889221 ]\n",
            " [18.090654 ]\n",
            " [16.019152 ]\n",
            " [22.91921  ]\n",
            " [14.908449 ]\n",
            " [ 0.9970049]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print 1st 10 values of ytest\n",
        "print(Y_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsePOh9ymGHY",
        "outputId": "fca08dda-43a7-48c7-84a0-55e79db5ab1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19.  9. 21. 10. 24. 18. 16. 23. 15.  1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "accuracy = model.evaluate(X_test, Y_test, verbose=1)\n",
        "\n",
        "# Print the accuracy in terms of MAE\n",
        "print(\"Test MAE:\", accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb7hTh_lmJA1",
        "outputId": "3a92f27f-8d11-48e0-c981-3de9dae8c4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 1s 15ms/step - loss: 0.1064 - mae: 0.1064\n",
            "Test MAE: 0.10644066333770752\n"
          ]
        }
      ]
    }
  ]
}